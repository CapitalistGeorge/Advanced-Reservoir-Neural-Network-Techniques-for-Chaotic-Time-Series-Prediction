{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import reservoirpy as rpy\n",
    "import seaborn as sns\n",
    "from reservoirpy.nodes import Ridge, Reservoir, Input\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import Ridge as Ridge_sklearn\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "import os\n",
    "from src.asc_itmo_lab.chaos_indic import HurstTraj, NoiseFactor, DimEmb, max_lyapunov, fourier_harmonic_count, ks_entropy_partition\n",
    "import skccm as ccm\n",
    "from skccm.utilities import train_test_split\n",
    "import warnings\n",
    "\n",
    "\n",
    "rpy.verbosity(0)  # no need to be too verbose here\n",
    "rpy.set_seed(23)  # make everything reproducible!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Data preprocessing and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Index Domclick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mredc_date = pd.read_csv(os.getcwd()+'/data/data_mredc_date.csv', index_col=0)\n",
    "data_mredc_date['date'] = pd.to_datetime(data_mredc_date['date'], yearfirst=True)\n",
    "data_mredc_date.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## USD/RUB currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "usd_rub = pd.read_excel(os.getcwd()+'/data/usd_rub.xlsx')\n",
    "usd_rub.info()\n",
    "usd_rub.drop(columns=['nominal', 'cdx'], inplace=True)\n",
    "usd_rub.rename(columns={'data':'date'}, inplace=True)\n",
    "usd_rub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Inflation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "infl = pd.read_excel(os.getcwd()+'/data/infl_msc.xls', decimal='.', skiprows=5, header=None)\n",
    "infl = infl.iloc[:, 2:].T.rename(columns={0: 'infl'})\n",
    "new_row = pd.DataFrame({'infl': [100.57]}) # инфляция по г.Москва, Январь 2025 г. к декабрю 2024 г.\n",
    "infl = pd.concat([infl, new_row], ignore_index=True)\n",
    "date_infl = pd.date_range('31-01-2017', periods=infl.shape[0], freq='ME')\n",
    "infl['date'] = date_infl\n",
    "\n",
    "# инфляция по г.Москва, декабрь 2016 (https://mosreg.ru/sobytiya/novosti/news-submoscow/inflyaciya-v-podmoskove-v-dekabre-proshlogo-goda-sostavila-0-4?utm_referrer=https%3A%2F%2Fwww.google.com%2F)\n",
    "new_row = pd.DataFrame({'infl': [100.4], 'date': ['2016-12-31']})\n",
    "new_row['date'] = pd.to_datetime(new_row['date'])\n",
    "# Объединяем новую строку и исходный DataFrame\n",
    "infl = pd.concat([new_row, infl], ignore_index=True)\n",
    "infl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "infl['infl'] = np.nancumprod(infl['infl']*0.01) #np.exp((infl['infl']*0.01-1).cumsum()) + np.log(1)\n",
    "infl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем дату в индекс\n",
    "infl.set_index('date', inplace=True)\n",
    "\n",
    "# Создаем полный еженедельный индекс (по средам)\n",
    "full_weekly_index = pd.date_range(data_mredc_date['date'].iloc[0], infl.index.max(), freq='D')\n",
    "\n",
    "# Переиндексируем данные инфляции\n",
    "infl_reindexed = infl.reindex(full_weekly_index)\n",
    "\n",
    "# Интерполируем с учетом времени (линейно между месячными точками)\n",
    "infl_interpolated = infl_reindexed.interpolate(method='time')\n",
    "\n",
    "# Сбрасываем индекс и переименовываем колонки\n",
    "infl_weekly = infl_interpolated.reset_index().rename(columns={'index': 'date'})\n",
    "\n",
    "infl_weekly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## ROISFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "roisfix = pd.read_csv(os.getcwd()+'/data/ROISFIX.csv', sep=';',\n",
    "                       header=1, encoding='cp1251', decimal=',')\n",
    "roisfix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "roisfix.rename(columns={'Дата ставки': 'date', '1W': 'roisfix_1w', '1M': 'roisfix_1m'}, inplace=True)\n",
    "roisfix['date'] = pd.to_datetime(roisfix['date'], dayfirst=True)\n",
    "roisfix = roisfix[['date', 'roisfix_1w', 'roisfix_1m']]\n",
    "roisfix.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Merging in one Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mredc_date = data_mredc_date.merge(usd_rub, how='left', on=['date'])\n",
    "data_mredc_date = data_mredc_date.merge(infl_weekly, how='left', on=['date'])\n",
    "data_mredc_date = data_mredc_date.merge(roisfix, how='left', on=['date'])\n",
    "data_mredc_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mredc_date['curs'].fillna(method='ffill', inplace=True)\n",
    "data_mredc_date['roisfix_1w'].fillna(method='ffill', inplace=True)\n",
    "data_mredc_date['roisfix_1m'].fillna(method='ffill', inplace=True)\n",
    "data_mredc_date['curs_MA'] = data_mredc_date['curs'].rolling(13).mean()\n",
    "data_mredc_date['curs_loged'] = np.log(data_mredc_date['curs']).diff()\n",
    "data_mredc_date['infl_loged'] = np.log(data_mredc_date['infl']).diff()\n",
    "\n",
    "data_mredc_date['MA_close'] = data_mredc_date['close'].rolling(13).mean()\n",
    "data_mredc_date['log_return_close'] = np.log(data_mredc_date['close'].rolling(13).mean()).diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(data_mredc_date['date'], data_mredc_date['close'])\n",
    "plt.ylabel('Value, rub')\n",
    "plt.xlabel('Time')\n",
    "plt.title('Index of the Moscow real estate market')\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(data_mredc_date['date'][13:], data_mredc_date['log_return_close'].dropna())\n",
    "plt.ylabel('Value, log return')\n",
    "plt.xlabel('Timestep')\n",
    "plt.title('Log return of Index')\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(data_mredc_date['date'], data_mredc_date['curs'], color='orange')\n",
    "plt.title('Currency Exchange USD/RUB, source - CBR')\n",
    "plt.ylabel('Value, rub')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(data_mredc_date['date'], data_mredc_date['infl'], color='red')\n",
    "plt.title('Inflation for all goods and services by month in Moscow')\n",
    "plt.ylabel('Value, %')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# 1\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(data_mredc_date['date'], data_mredc_date['close'], label='Close')\n",
    "plt.plot(data_mredc_date['date'], data_mredc_date['MA_close'], label='MA Close')\n",
    "plt.title('Index of the Moscow real estate market')\n",
    "plt.ylabel('Value, RUB')\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# 2\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(data_mredc_date['date'], data_mredc_date['curs'], color='orange')\n",
    "plt.title('Currency Exchange USD/RUB')\n",
    "plt.ylabel('Value, RUB')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()\n",
    "\n",
    "# 3\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(data_mredc_date['date'], data_mredc_date['infl'], color='green')\n",
    "plt.title('Monthly Inflation (Moscow)')\n",
    "plt.ylabel('Value, %')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()\n",
    "\n",
    "# 4\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(data_mredc_date['date'], data_mredc_date['roisfix_1m'], label='1M')\n",
    "plt.plot(data_mredc_date['date'], data_mredc_date['roisfix_1w'], label='1W')\n",
    "plt.title('ROISFIX - RUONIA Overnight Interest Rate Swap')\n",
    "plt.ylabel('Value, %')\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(data_mredc_date['date'], data_mredc_date['roisfix_1m'], label='1 week', color='blue')\n",
    "plt.plot(data_mredc_date['date'], data_mredc_date['roisfix_1w'], label='1 month', color='c')\n",
    "plt.title('ROISFIX - RUONIA Overnight Interest Rate Swap')\n",
    "plt.ylabel('Value, %')\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем фигуру и первую ось (ось Y для рублей)\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color1 = 'tab:blue'\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Index value (rub)', color=color1)\n",
    "ax1.plot(data_mredc_date['date'], data_mredc_date['close'], color=color1, label='Index Domclick')\n",
    "ax1.plot(data_mredc_date['date'], data_mredc_date['close'].rolling(13).mean(), color='blue', alpha=0.75, label='Mean Index Domclick')\n",
    "ax1.tick_params(axis='y', labelcolor=color1)\n",
    "\n",
    "# Создаем вторую ось Y, общую с осью X\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "color2 = 'tab:orange'\n",
    "ax2.set_ylabel('rub per $', color=color2)\n",
    "ax2.plot(data_mredc_date['date'], data_mredc_date['curs'], color='orange', label='USD/RUB')\n",
    "ax2.plot(data_mredc_date['date'], data_mredc_date['curs'].rolling(13).mean(), color='orange', alpha=0.45, label='Mean USD/RUB')\n",
    "ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "# Добавляем заголовок и отображаем график\n",
    "plt.title('The composite index of the Moscow real estate market')\n",
    "fig.tight_layout()\n",
    "plt.grid()\n",
    "\n",
    "# Получаем линии и метки с обеих осей\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "\n",
    "# Объединяем и отображаем общую легенду\n",
    "ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "# Estimate chaotic measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimations = []\n",
    "\n",
    "for series_name in data_mredc_date.columns[1:]:\n",
    "    # Only process if enough data points\n",
    "    if len(data_mredc_date[series_name]) < 1:\n",
    "        continue\n",
    "    \n",
    "    # Compute metrics\n",
    "    _, _, hurst_exponent, _ = HurstTraj(data_mredc_date[series_name].dropna())\n",
    "    noise = NoiseFactor(data_mredc_date[series_name].dropna())\n",
    "    _, corr_dim, _ = DimEmb(data_mredc_date[series_name].dropna())\n",
    "    lyap_max = max_lyapunov(data_mredc_date[series_name].dropna().values)\n",
    "    ks_ent = ks_entropy_partition(data_mredc_date[series_name].dropna())\n",
    "    fourier_count = fourier_harmonic_count(data_mredc_date[series_name].dropna())\n",
    "    \n",
    "    estimations.append({\n",
    "        'series': series_name,\n",
    "        'hurst': hurst_exponent,\n",
    "        'noise_factor': noise,\n",
    "        'corr_dim': corr_dim,\n",
    "        'lyap_max': lyap_max,\n",
    "        'ks_entropy': ks_ent,\n",
    "        'fourier_harmonics': fourier_count\n",
    "    })\n",
    "\n",
    "measures_df = pd.DataFrame(estimations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(measures_df,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# CCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossCorr(datax, datay, maxlag=52):\n",
    "    \"\"\"\n",
    "    Find the lag (1…maxlag−1) that maximizes the absolute Spearman correlation\n",
    "    between datax and datay shifted by that lag.\n",
    "    Returns: (best_lag, best_correlation)\n",
    "    \"\"\"\n",
    "    dx = pd.Series(datax)\n",
    "    dy = pd.Series(datay)\n",
    "    best_corr = 0.0\n",
    "    best_lag  = 1\n",
    "    for lag in range(1, maxlag):\n",
    "        c = abs(dx.corr(dy.shift(lag), method='spearman'))\n",
    "        if c > best_corr:\n",
    "            best_corr = c\n",
    "            best_lag  = lag\n",
    "    return best_lag, best_corr\n",
    "\n",
    "def ccm_test(x1, x2, maxlag=52):\n",
    "    \"\"\"\n",
    "    Identify the optimal lag and embedding dimension for CCM between x1 (target)\n",
    "    and x2 (predictor). Returns (lag, embed, max_corr).\n",
    "    \"\"\"\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # 1) pick lag via Spearman Cross‐correlation\n",
    "    lag, _ = CrossCorr(x1, x2, maxlag=maxlag)\n",
    "\n",
    "    best_score = -np.inf\n",
    "    best_embed = None\n",
    "\n",
    "    # 2) sweep embedding dimension\n",
    "    for E in range(2, 6):\n",
    "        e1 = ccm.Embed(x1)\n",
    "        e2 = ccm.Embed(x2)\n",
    "        X1 = e1.embed_vectors_1d(lag, E)\n",
    "        X2 = e2.embed_vectors_1d(lag, E)\n",
    "\n",
    "        x1_tr, x1_te, x2_tr, x2_te = train_test_split(X1, X2, percent=0.9)\n",
    "        lib_lens = np.unique(np.linspace(10, len(x1_tr), num=20, dtype=int))\n",
    "\n",
    "        model = ccm.CCM(score_metric='corrcoef')\n",
    "        model.fit(x1_tr, x2_tr)\n",
    "        model.predict(x1_te, x2_te, lib_lengths=lib_lens)\n",
    "        sc1, _ = model.score()  # sc1 is the array of corrcoefs for X1→X2\n",
    "\n",
    "        if max(sc1) > best_score:\n",
    "            best_score = max(sc1)\n",
    "            best_embed = E\n",
    "\n",
    "    return lag, best_embed, best_score\n",
    "\n",
    "def choose_preds_ccm(df, target_col, top_n=5, maxlag=52):\n",
    "    \"\"\"\n",
    "    Rank all columns in df (except target_col) by their CCM causality score\n",
    "    with target_col, and return the top_n predictors.\n",
    "    \"\"\"\n",
    "    # 1) drop any rows with NaNs in target or predictors\n",
    "    preds = [c for c in df.columns if c != target_col]\n",
    "    df_clean = df.dropna(subset=[target_col] + preds).reset_index(drop=True)\n",
    "\n",
    "    # 2) scale target to [-1,1]\n",
    "    y = df_clean[target_col].values\n",
    "    y_scaled = y / np.max(np.abs(y))\n",
    "\n",
    "    results = []\n",
    "    for pred in preds:\n",
    "        x = df_clean[pred].values\n",
    "        # normalize predictor to [0,1]\n",
    "        x_norm = (x - x.min())/(x.max() - x.min())\n",
    "\n",
    "        lag, embed, score = ccm_test(y_scaled, x_norm, maxlag=maxlag)\n",
    "        results.append({\n",
    "            'predictor': pred,\n",
    "            'lag':       lag,\n",
    "            'embed':     embed,\n",
    "            'score':     score\n",
    "        })\n",
    "\n",
    "    # 3) sort by descending CCM score and return top_n\n",
    "    return sorted(results, key=lambda d: d['score'], reverse=True)[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mredc_date.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = choose_preds_ccm(data_mredc_date.drop(columns=['date', 'close', 'log_return_close', 'curs_loged', 'infl_loged']).dropna(),\n",
    "     target_col='MA_close', top_n=5)\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_preds_ccm(data_mredc_date.drop(columns=['date', 'close', 'MA_close']).dropna(),\n",
    "     target_col='log_return_close', top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = data_mredc_date.copy()\n",
    "X0 = X0.drop(columns=['date', 'close', 'log_return_close']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_info = {d['predictor']:(d['lag'], d['embed']) for d in embed_info_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmd = data_mredc_date.copy()\n",
    "dmd['infl_laged'] = dmd['infl'].shift(19)\n",
    "dmd['curs_MA_laged'] = dmd['curs_MA'].shift(24)\n",
    "dmd['curs_laged'] = dmd['curs'].shift(31)\n",
    "dmd['roisfix_1m_laged'] = dmd['roisfix_1m'].shift(2)\n",
    "dmd['roisfix_1w_laged'] = dmd['roisfix_1w'].shift(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedESN_FAN:\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 reservoir_size=100,\n",
    "                 spectral_radius=0.9,\n",
    "                 sparsity=0.1,\n",
    "                 ridge_alpha=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 poly_order=2,\n",
    "                 fan_dp=5,\n",
    "                 seed=23):\n",
    "        \"\"\"\n",
    "        input_dim : dimensionality of X (features per timestep)\n",
    "        fan_dp    : number of Fourier terms (dp in the FAN paper)\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.poly = PolynomialFeatures(degree=poly_order, include_bias=False)\n",
    "        self.fan_dp = fan_dp\n",
    "\n",
    "        # placeholders; actual Win/W init happens in fit()\n",
    "        self.Win = None\n",
    "        self.W   = None\n",
    "\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.sparsity = sparsity\n",
    "        self.leaking_rate = leaking_rate\n",
    "\n",
    "        self.ridge = Ridge_sklearn(alpha=ridge_alpha)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.input_scaler = StandardScaler()\n",
    "\n",
    "    def initialize_weights(self, X):\n",
    "        # input‐distribution aware Win\n",
    "        inp_mean, inp_std = X.mean(axis=0), X.std(axis=0)\n",
    "        mu, sigma = inp_mean.mean(), inp_std.mean()\n",
    "        self.Win = np.random.normal(mu, sigma, (self.reservoir_size, X.shape[1] + 1))\n",
    "\n",
    "        # sparse W with spectral radius\n",
    "        W = np.random.rand(self.reservoir_size, self.reservoir_size) - 0.5\n",
    "        W[np.random.rand(*W.shape) > self.sparsity] = 0\n",
    "        W *= self.spectral_radius / np.max(np.abs(np.linalg.eigvals(W)))\n",
    "        self.W = W\n",
    "\n",
    "    def _update(self, state, u):\n",
    "        # standard ESN update\n",
    "        # pre = self.Win @ np.concatenate(([1], u)) + self.W @ state\n",
    "        # return np.tanh(pre)\n",
    "        pre_activation = self.Win @ np.concatenate(([1], u)) + self.W @ state\n",
    "        new_state = np.tanh(pre_activation)\n",
    "        \n",
    "        # Integrate leaking rate\n",
    "        updated_state = (1 - self.leaking_rate) * state + self.leaking_rate * new_state\n",
    "        return updated_state\n",
    "\n",
    "    def _fourier_features(self, X):\n",
    "        # X: (n_samples, n_features)\n",
    "        # return: (n_samples, 2*fan_dp*n_features)\n",
    "        # FAN: explicit Fourier series terms sin(2πk x), cos(2πk x)\n",
    "        features = []\n",
    "        for k in range(1, self.fan_dp + 1):\n",
    "            features.append(np.sin(2 * np.pi * k * X))\n",
    "            features.append(np.cos(2 * np.pi * k * X))\n",
    "        return np.hstack(features)\n",
    "    \n",
    "    # def _fft_features(self, X, n_coeffs):\n",
    "    #     # X: (T, n) time series\n",
    "    #     # return first n_coeffs magnitudes per dimension\n",
    "    #     coeffs = np.abs(fft(X, axis=0))[:n_coeffs]  # shape (n_coeffs, n)\n",
    "    #     return np.tile(coeffs.flatten(), (X.shape[0], 1))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: shape (T, input_dim)\n",
    "        y: shape (T,) or (T, output_dim)\n",
    "        \"\"\"\n",
    "        # init reservoir\n",
    "        self.initialize_weights(X)\n",
    "\n",
    "        # collect reservoir states\n",
    "        T = X.shape[0]\n",
    "        states = np.zeros((T, self.reservoir_size))\n",
    "        state = np.zeros(self.reservoir_size)\n",
    "        for t in range(T):\n",
    "            state = self._update(state, X[t])\n",
    "            states[t] = state\n",
    "\n",
    "        X_scaled = self.input_scaler.fit_transform(X)\n",
    "        # polynomial features\n",
    "        P = self.poly.fit_transform(X_scaled)\n",
    "        # Fourier analysis network features\n",
    "        F = self._fourier_features(X_scaled)\n",
    "\n",
    "        # # combine all\n",
    "        # H = np.hstack([states, P, F])\n",
    "\n",
    "        # # scale & fit readout\n",
    "        # Hs = self.scaler.fit_transform(H)\n",
    "        # self.ridge.fit(Hs, y)\n",
    "\n",
    "        H = np.hstack([states, P, F])\n",
    "        self.scaler.fit(H)\n",
    "        # prevent division by zero in .transform()\n",
    "        self.scaler.scale_[self.scaler.scale_ == 0.0] = 1.0\n",
    "        Hs = self.scaler.transform(H)\n",
    "        self.ridge.fit(Hs, y)\n",
    "\n",
    "\n",
    "    def predict(self, X, generative_steps=None):\n",
    "        \"\"\"\n",
    "        If X is (T, input_dim) and generative_steps is None, this is open-loop:\n",
    "          returns readout(X)\n",
    "        If generative_steps is an int > 0, we perform:\n",
    "          - use X[-1] as u0, then recursively predict next u's.\n",
    "        \"\"\"\n",
    "        if generative_steps is None:\n",
    "            # one‐shot prediction (teacher forcing)\n",
    "            T = X.shape[0]\n",
    "            states = np.zeros((T, self.reservoir_size))\n",
    "            state = np.zeros(self.reservoir_size)\n",
    "            for t in range(T):\n",
    "                state = self._update(state, X[t])\n",
    "                states[t] = state\n",
    "\n",
    "            P = self.poly.transform(X)\n",
    "            F = self._fourier_features(X)\n",
    "            H = np.hstack([states, P, F])\n",
    "            Hs = self.scaler.transform(H)\n",
    "            return self.ridge.predict(Hs)\n",
    "\n",
    "        # generative forecasting\n",
    "        u = X[-1].copy()      # last observed input\n",
    "        state = np.zeros(self.reservoir_size)\n",
    "        preds = []\n",
    "        for _ in range(generative_steps):\n",
    "            state = self._update(state, u.reshape(-1))\n",
    "            # build feature row\n",
    "            # P = self.poly.transform(u.reshape(1, -1))\n",
    "            # F = self._fourier_features(u.reshape(1, -1))\n",
    "            u_scaled = self.input_scaler.transform(u.reshape(1, -1))\n",
    "            clip = 3.0  # you can tune this (e.g. 3 standard deviations)\n",
    "            u_scaled = np.clip(u_scaled, -clip, clip)\n",
    "\n",
    "            P = self.poly.transform(u_scaled)\n",
    "            F = self._fourier_features(u_scaled)\n",
    "            h = np.hstack([state, P.ravel(), F.ravel()]).reshape(1, -1)\n",
    "            h_s = self.scaler.transform(h)\n",
    "            u_next = self.ridge.predict(h_s)\n",
    "            preds.append(u_next.ravel())\n",
    "            u = u_next  # feed back\n",
    "\n",
    "        return np.vstack(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 200\n",
    "leak_rate = 0.9\n",
    "spectral_radius = 1.1\n",
    "input_scaling = 1.0\n",
    "connectivity = 0.5\n",
    "input_connectivity = 0.5\n",
    "regularization = 1e-8\n",
    "seed = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_esn(input_dim):\n",
    "    input_one = Input(input_dim=input_dim)\n",
    "    reservoir_one = Reservoir(units, input_scaling=input_scaling, sr=spectral_radius,\n",
    "                        lr=leak_rate, rc_connectivity=connectivity,\n",
    "                        input_connectivity=input_connectivity, seed=seed)\n",
    "    \n",
    "    readout_one   = Ridge(input_dim, ridge=regularization)\n",
    "\n",
    "    return input_one >> reservoir_one >> readout_one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(\n",
    "    model_factory,\n",
    "    time_series,\n",
    "    time_delta,\n",
    "    cv_type=\"expanding\",\n",
    "    train_size=None,\n",
    "    drop_step=None,\n",
    "    train_full=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform multi‐step MAPE CV on a 1D series with either expanding or rolling windows,\n",
    "    working directly on the provided real‐scale time_series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_factory : callable\n",
    "        Constructor for your model (e.g. EnhancedESN_FAN), must accept input_dim=1\n",
    "        and implement .fit(X,y) and .run(u).\n",
    "    time_series : pd.Series or 1D array\n",
    "        The raw input sequence.\n",
    "    time_delta : int\n",
    "        Forecast horizon for each fold.\n",
    "    cv_type : {\"expanding\",\"rolling\"}\n",
    "        \"expanding\": train=[0:fold*Δ], test=next Δ points.\n",
    "        \"rolling\" : train=[start:start+window_size], test=next Δ points.\n",
    "    window_size : int, optional\n",
    "        Required if cv_type==\"rolling\". Fixed length of each training window.\n",
    "    train_full : bool\n",
    "        If True, refit on the entire series at the end and return that model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    final_model : object or None\n",
    "        The model refit on the full series if train_full else None.\n",
    "    history_mape : List[float]\n",
    "        One MAPE per fold.\n",
    "    \"\"\"\n",
    "    ts = np.asarray(time_series)\n",
    "    L = len(time_series)\n",
    "\n",
    "    if cv_type not in (\"expanding\", \"rolling\"):\n",
    "        raise ValueError(\"cv_type must be 'expanding' or 'rolling'\")\n",
    "\n",
    "    if cv_type == \"rolling\" and drop_step is None:\n",
    "        raise ValueError(\"Must specify window_size for rolling CV\")\n",
    "    \n",
    "    history_mape = []\n",
    "    history_mae = []\n",
    "\n",
    "    if cv_type == \"expanding\":\n",
    "        n_folds = (L-train_size) // time_delta\n",
    "        F = (L-train_size) % time_delta  # Остаточная часть (конец ряда)\n",
    "        for fold in range(0, n_folds+1):\n",
    "            train_end = train_size + fold * time_delta\n",
    "            test_start = train_end\n",
    "            test_end   = train_end + time_delta\n",
    "            if test_end > L:\n",
    "                break\n",
    "\n",
    "            # Build train and test slices\n",
    "            X_tr = ts[:train_end-1].reshape(-1, 1)\n",
    "            y_tr = ts[1:train_end].reshape(-1, 1)\n",
    "            y_true = ts[test_start:test_end].reshape(-1, 1)\n",
    "\n",
    "            # Fit model\n",
    "            model = model_factory\n",
    "            model.fit(X_tr, y_tr)\n",
    "\n",
    "            # Generative Δ-step forecast\n",
    "            preds = model.predict(y_tr, generative_steps=time_delta)\n",
    "            \n",
    "            # Compute MAPE\n",
    "            mape = mean_absolute_percentage_error(y_true, preds) * 100\n",
    "            history_mape.append(mape)\n",
    "\n",
    "            # Compute MAE\n",
    "            mae = mean_absolute_error(y_true, preds)\n",
    "            history_mae.append(mae)\n",
    "\n",
    "        if F > 0:\n",
    "            train_end = L - F\n",
    "            test_start = train_end\n",
    "            test_end = L  # Используем весь остаток\n",
    "\n",
    "            X_tr = ts[:train_end - 1].reshape(-1, 1)\n",
    "            y_tr = ts[1:train_end].reshape(-1, 1)\n",
    "            y_true = ts[test_start:test_end].reshape(-1, 1)\n",
    "\n",
    "            # Fit model\n",
    "            model = model_factory\n",
    "            model.fit(X_tr, y_tr)\n",
    "\n",
    "            # Generative Δ-step forecast\n",
    "            preds = model.predict(y_tr, generative_steps=F)\n",
    "            # Compute MAPE\n",
    "            mape = mean_absolute_percentage_error(y_true, preds) * 100\n",
    "            history_mape.append(mape)\n",
    "\n",
    "            # Compute MAE\n",
    "            mae = mean_absolute_error(y_true, preds)\n",
    "            history_mae.append(mae)\n",
    "\n",
    "    else:  # rolling\n",
    "        for start in range(0, L-train_size-time_delta+1, drop_step):\n",
    "            train_start = start\n",
    "            train_end   = start+train_size+time_delta\n",
    "            test_start  = train_end\n",
    "            test_end    = test_start + time_delta\n",
    "            if test_end > L:\n",
    "                break\n",
    "\n",
    "            X_tr = ts[train_start:train_end-1].reshape(-1, 1)\n",
    "            y_tr = ts[train_start+1:train_end].reshape(-1, 1)\n",
    "            y_true = ts[test_start:test_end].reshape(-1, 1)\n",
    "\n",
    "            model = model_factory\n",
    "            model.fit(X_tr, y_tr)\n",
    "\n",
    "            preds = model.predict(y_tr, generative_steps=time_delta)\n",
    "            # Compute MAPE\n",
    "            mape = mean_absolute_percentage_error(y_true, preds) * 100\n",
    "            history_mape.append(mape)\n",
    "\n",
    "            # Compute MAE\n",
    "            mae = mean_absolute_error(y_true, preds)\n",
    "            history_mae.append(mae)\n",
    "\n",
    "    final_model = None\n",
    "    if train_full:\n",
    "        X_all = ts[:-1].reshape(-1,1)\n",
    "        y_all = ts[1: ].reshape(-1,1)\n",
    "        final_model = model_factory.fit(X_all, y_all)\n",
    "\n",
    "    return final_model, history_mape, history_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## One-dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "esn_fan = EnhancedESN_FAN(input_dim=1, reservoir_size=200, spectral_radius=1.1, leaking_rate=0.9,\n",
    "                      sparsity=0.5, ridge_alpha=1e-8, poly_order=1, fan_dp=5, seed=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mredc_date[['date','close', 'curs', 'infl']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_one, one_history, one_history_mae = cross_validation(esn_fan, dmd.dropna()['MA_close'], time_delta=52, train_size=104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_one_sch2, one_history_sch2, one_history_sch2_mae = cross_validation(esn_fan, dmd.dropna()['MA_close'],\n",
    "                                                                           time_delta=52, train_size=104,\n",
    "                                                                             cv_type='rolling', drop_step=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_multi(\n",
    "    model_factory,\n",
    "    time_series,\n",
    "    time_delta,\n",
    "    cv_type=\"expanding\",\n",
    "    train_size=None,\n",
    "    train_full=False,\n",
    "    drop_step=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform multi-step MAPE cross-validation on multivariate time series,\n",
    "    computing MAPE individually for each variable.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_factory : callable\n",
    "        Constructor for EnhancedESN_FAN, accepts input_dim and provides methods fit(X,y) and predict(X, generative_steps).\n",
    "    time_series : pd.DataFrame or np.ndarray\n",
    "        Multivariate series (shape: [T, num_features]).\n",
    "    time_delta : int\n",
    "        Forecast horizon per fold.\n",
    "    cv_type : {\"expanding\", \"rolling\"}\n",
    "        Cross-validation type.\n",
    "    window_size : int, optional\n",
    "        Training window size if rolling CV.\n",
    "    train_full : bool\n",
    "        Train on full data after CV if True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    final_model : object or None\n",
    "        Model trained on full series if train_full else None.\n",
    "    history_mape : dict\n",
    "        Dict of variable-wise MAPE lists per fold.\n",
    "    \"\"\"\n",
    "    ts = np.asarray(time_series)\n",
    "    num_obs, num_features = ts.shape\n",
    "    L = len(time_series)\n",
    "\n",
    "    if cv_type not in (\"expanding\", \"rolling\"):\n",
    "        raise ValueError(\"cv_type must be 'expanding' or 'rolling'\")\n",
    "\n",
    "    if cv_type == \"rolling\" and drop_step is None:\n",
    "        raise ValueError(\"Must specify window_size for rolling CV\")\n",
    "\n",
    "    history_mape = {f\"var_{i}\": [] for i in range(num_features)}\n",
    "    history_mae = {f\"var_{i}\": [] for i in range(num_features)}\n",
    "\n",
    "    if cv_type == \"expanding\":\n",
    "        n_folds = (L-train_size) // time_delta\n",
    "        F = (L-train_size) % time_delta  # Остаточная часть (конец ряда)\n",
    "        for fold in range(0, n_folds+1):\n",
    "            train_end = train_size + fold * time_delta\n",
    "            test_start = train_end\n",
    "            test_end = train_end + time_delta\n",
    "\n",
    "            if test_end > num_obs:\n",
    "                break\n",
    "\n",
    "            X_tr = ts[:train_end-1]\n",
    "            y_tr = ts[1:train_end]\n",
    "            y_true = ts[test_start:test_end]\n",
    "\n",
    "            model = model_factory\n",
    "            model.fit(X_tr, y_tr)\n",
    "\n",
    "            preds = model.predict(y_tr, generative_steps=time_delta)\n",
    "\n",
    "            for i in range(num_features):\n",
    "                mape = mean_absolute_percentage_error(y_true[:, i], preds[:, i]) * 100\n",
    "                history_mape[f\"var_{i}\"].append(mape)\n",
    "\n",
    "        if F > 0:\n",
    "            train_end = L - F\n",
    "            test_start = train_end\n",
    "            test_end = L  # Используем весь остаток\n",
    "\n",
    "            X_tr = ts[:train_end - 1]\n",
    "            y_tr = ts[1:train_end]\n",
    "            y_true = ts[test_start:test_end]\n",
    "\n",
    "            # Fit model\n",
    "            model = model_factory\n",
    "            model.fit(X_tr, y_tr)\n",
    "\n",
    "            # Generative Δ-step forecast\n",
    "            preds = model.predict(y_tr, generative_steps=F)\n",
    "            # Compute MAPE\n",
    "            for i in range(num_features):\n",
    "                mape = mean_absolute_percentage_error(y_true[:, i], preds[:, i]) * 100\n",
    "                history_mape[f\"var_{i}\"].append(mape)\n",
    "\n",
    "                mae = mean_absolute_error(y_true[:, i], preds[:, i])\n",
    "                history_mae[f\"var_{i}\"].append(mae)\n",
    "\n",
    "    else:  # rolling\n",
    "        for start in range(0, L-train_size-time_delta+1, drop_step):\n",
    "            train_start = start\n",
    "            train_end   = start+train_size+time_delta\n",
    "            test_start  = train_end\n",
    "            test_end    = test_start + time_delta\n",
    "            if test_end > L:\n",
    "                break\n",
    "\n",
    "            X_tr = ts[train_start:train_end-1]\n",
    "            y_tr = ts[train_start+1:train_end]\n",
    "            y_true = ts[test_start:test_end]\n",
    "\n",
    "            model = model_factory\n",
    "            model.fit(X_tr, y_tr)\n",
    "\n",
    "            preds = model.predict(y_tr, generative_steps=time_delta)\n",
    "            # Compute MAPE\n",
    "            for i in range(num_features):\n",
    "                mape = mean_absolute_percentage_error(y_true[:, i], preds[:, i]) * 100\n",
    "                history_mape[f\"var_{i}\"].append(mape)\n",
    "\n",
    "                mae = mean_absolute_error(y_true[:, i], preds[:, i])\n",
    "                history_mae[f\"var_{i}\"].append(mae)\n",
    "\n",
    "    final_model = None\n",
    "    if train_full:\n",
    "        X_all = ts[:-1]\n",
    "        y_all = ts[1:]\n",
    "        final_model = model_factory\n",
    "        final_model.fit(X_all, y_all)\n",
    "\n",
    "    return final_model, history_mape, history_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "esn_fan_multi = EnhancedESN_FAN(input_dim=6, reservoir_size=200, spectral_radius=1.1, leaking_rate=0.9,\n",
    "                      sparsity=0.5, ridge_alpha=1e-8, poly_order=1, fan_dp=5, seed=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi, multi_history, multi_history_mae = cross_validation_multi(esn_fan_multi,\n",
    "                                                                        dmd.dropna()[['MA_close', 'curs', 'curs_MA',\n",
    "                                                                                'infl']].values,\n",
    "                                                                        time_delta=52, train_size=104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi_sch2, multi_history_sch2, multi_history_sch2_mae = cross_validation_multi(esn_fan_multi,\n",
    "                                                                                       dmd.dropna()[['MA_close',\n",
    "                                                                                            'curs_laged', 'curs_MA',\n",
    "                                                                                            'infl', 'curs_MA_laged',\n",
    "                                                                                            'infl_laged']].values,\n",
    "                                                                                       cv_type='rolling', time_delta=52,\n",
    "                                                                                         train_size=104, drop_step=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "# Box-plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "## Expanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем DataFrame для визуализации\n",
    "data = pd.DataFrame({\n",
    "    'One-dimensional': np.array(one_history[:]),\n",
    "    'Multi-dimensional': np.array(multi_history['var_0']),\n",
    "})\n",
    "\n",
    "# Преобразуем данные в длинный формат\n",
    "data_melted = data.melt(var_name='Model', value_name='MAPE')\n",
    "\n",
    "# Настраиваем размер графика\n",
    "plt.figure(figsize=(7, 10))\n",
    "\n",
    "# Рисуем boxplot\n",
    "sns.boxplot(\n",
    "    x='Model', \n",
    "    y='MAPE', \n",
    "    data=data_melted,\n",
    "    hue='Model',\n",
    "    legend=False,\n",
    "    showmeans=True,  # Показываем средние значения\n",
    "    meanprops={'marker':'o', 'markerfacecolor':'black'}\n",
    ")\n",
    "\n",
    "# Добавляем заголовок и подписи\n",
    "plt.title(\"Box-plots of MAPE Errors by cross-validation (26 points)\", fontsize=14)\n",
    "plt.xlabel(\"Model Type\", fontsize=12)\n",
    "plt.ylabel(\"MAPE (%)\", fontsize=12)\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Добавляем аннотации\n",
    "plt.text(\n",
    "    x=0.5, y=-0.15, \n",
    "    s='Note: Black circles represent mean values',\n",
    "    fontsize=10, ha='center', transform=plt.gca().transAxes\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(one_history, label='one-dim')\n",
    "plt.plot(multi_history['var_0'], label='multi-dim')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Fold number')\n",
    "plt.ylabel('MAPE, %')\n",
    "plt.title('MAPE by expanding cross-validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "## Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем DataFrame для визуализации\n",
    "data = pd.DataFrame({\n",
    "    'One-dimensional': np.array(one_history_sch2),\n",
    "    'Multi-dimensional': np.array(multi_history_sch2['var_0']),\n",
    "    # 'LightGBM': np.array(history_mape_lg)\n",
    "})\n",
    "\n",
    "# Преобразуем данные в длинный формат\n",
    "data_melted = data.melt(var_name='Model', value_name='MAPE')\n",
    "\n",
    "# Настраиваем размер графика\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Рисуем boxplot\n",
    "sns.boxplot(\n",
    "    x='Model', \n",
    "    y='MAPE', \n",
    "    data=data_melted,\n",
    "    hue='Model',\n",
    "    legend=False,\n",
    "    showmeans=True,  # Показываем средние значения\n",
    "    meanprops={'marker':'o', 'markerfacecolor':'black'}\n",
    ")\n",
    "\n",
    "# Добавляем заголовок и подписи\n",
    "plt.title(\"Box-plots of MAPE Errors by cross-validation (rolling)\", fontsize=14)\n",
    "plt.xlabel(\"Model Type\", fontsize=12)\n",
    "plt.ylabel(\"MAPE (%)\", fontsize=12)\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Добавляем аннотации\n",
    "plt.text(\n",
    "    x=0.5, y=-0.15, \n",
    "    s='Note: Black circles represent mean values',\n",
    "    fontsize=10, ha='center', transform=plt.gca().transAxes\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history_mape_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем DataFrame для визуализации\n",
    "data = pd.DataFrame({\n",
    "    'One-dimensional': np.array(one_history_sch2),\n",
    "    'Multi-dimensional': np.array(multi_history_sch2['var_0']),\n",
    "    'LightGBM': np.array(history_mape_lg)\n",
    "})\n",
    "\n",
    "# Преобразуем данные в длинный формат\n",
    "data_melted = data.melt(var_name='Model', value_name='MAPE')\n",
    "\n",
    "# Настраиваем размер графика\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Рисуем boxplot\n",
    "sns.boxplot(\n",
    "    x='Model', \n",
    "    y='MAPE', \n",
    "    data=data_melted,\n",
    "    hue='Model',\n",
    "    legend=False,\n",
    "    showmeans=True,  # Показываем средние значения\n",
    "    meanprops={'marker':'o', 'markerfacecolor':'black'}\n",
    ")\n",
    "\n",
    "# Добавляем заголовок и подписи\n",
    "plt.title(\"Box-plots of MAPE Errors by cross-validation (rolling)\", fontsize=14)\n",
    "plt.xlabel(\"Model Type\", fontsize=12)\n",
    "plt.ylabel(\"MAPE (%)\", fontsize=12)\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Добавляем аннотации\n",
    "plt.text(\n",
    "    x=0.5, y=-0.15, \n",
    "    s='Note: Black circles represent mean values',\n",
    "    fontsize=10, ha='center', transform=plt.gca().transAxes\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pd.DataFrame({\n",
    "    'Model': ['ESN-FT (one-dim)', 'ESN-FT (mult-dim)', 'LightGBM'],\n",
    "    'MAPE': [np.array(one_history_sch2).mean(), np.array(multi_history_sch2['var_0']).mean(),np.array(history_mape_lg).mean()],\n",
    "    'MAE': [np.array(one_history_sch2_mae).mean(), np.array(multi_history_sch2_mae['var_0']).mean(),np.array(lg_mae).mean()]\n",
    "    }).head(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(one_history_sch2, label='one-dim')\n",
    "plt.plot(multi_history_sch2['var_0'], label='multi-dim')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Fold number')\n",
    "plt.ylabel('MAPE, %')\n",
    "plt.title('MAPE by rolling cross-validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# многомерный простой vs одномерный наш "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back to real from log\n",
    "\n",
    "def back_to_real(loged_array, init):\n",
    "    to_real = np.exp(loged_array.cumsum() + np.log(init))\n",
    "    return to_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calc_metrics(y_true, y_pred, metric_list):\n",
    "        \"\"\"\n",
    "        Calculate chosen metrics: MSE, MAE, MAPE\n",
    "        Return a dict with each metric: value\n",
    "        Round results to 2 decimals.\n",
    "        \"\"\"\n",
    "        eps = 1e-9  # to avoid div-by-zero\n",
    "        results = {}\n",
    "\n",
    "        if len(y_true.shape) == 2 and y_true.shape[1] == 1:\n",
    "            # flatten for univariate\n",
    "            y_true = y_true.flatten()\n",
    "            y_pred = y_pred.flatten()\n",
    "\n",
    "        for metric in metric_list:\n",
    "            if metric.upper() == 'MSE':\n",
    "                mse_val = np.mean((y_true - y_pred) ** 2)\n",
    "                results['MSE'] = round(mse_val, 2)\n",
    "            elif metric.upper() == 'MAE':\n",
    "                mae_val = np.mean(np.abs(y_true - y_pred))\n",
    "                results['MAE'] = round(mae_val, 2)\n",
    "            elif metric.upper() == 'MAPE':\n",
    "                mape_val = np.mean(np.abs((y_true - y_pred) / (y_true + eps))) * 100\n",
    "                results['MAPE'] = round(mape_val, 2)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported metric: {metric}\")\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#одномерный обычный\n",
    "def cross_validation_esn_base(func, time_series, time_delta, metric_list, schema='schema_1', drop_step=1, train_size=78):\n",
    "\n",
    "    if schema == 'schema_1':\n",
    "        L = len(time_series)\n",
    "        N = L // time_delta\n",
    "        F = L % time_delta  # Остаточная часть (конец ряда)\n",
    "\n",
    "        if N <= 1:\n",
    "            raise ValueError(\"Change time_delta, not enough data for CV\")\n",
    "        \n",
    "        history_metric = {metric: [] for metric in metric_list}\n",
    "        initial_series = back_to_real(time_series, data_mredc_date['close'][0])\n",
    "\n",
    "        for n in range(1, N+1):\n",
    "\n",
    "            # Индексы для разделения данных\n",
    "            train_end = time_delta * n\n",
    "            test_start = train_end\n",
    "            test_end = test_start + time_delta\n",
    "\n",
    "            # Проверка выхода за границы данных\n",
    "            if test_end > len(initial_series):\n",
    "                break\n",
    "\n",
    "            # Разделение данных\n",
    "            X_train = time_series[:train_end - 1].values.reshape(-1, 1)\n",
    "            y_train = time_series[1:train_end].values.reshape(-1, 1)\n",
    "\n",
    "            y_test = initial_series[test_start:test_end].values.reshape(-1,1)\n",
    "\n",
    "            model = func(1)\n",
    "            model = model.fit(X_train, y_train)\n",
    "\n",
    "            current = X_train[-1]\n",
    "            pred_logs = []\n",
    "            for i in range(time_delta):\n",
    "                pred_logs.append(model.run(current))\n",
    "                current = pred_logs[i]\n",
    "            # print(np.array(pred_logs).flatten().reshape(-1,1).shape, time_series[:k_folds*time_delta*n].values.reshape(-1, 1).shape)\n",
    "            pred_real = back_to_real(np.concatenate((time_series[:time_delta*n].values.reshape(-1, 1), np.array(pred_logs).flatten().reshape(-1,1))),\n",
    "                                      data_mredc_date['close'][0])[time_delta*n:]\n",
    "            # print(y_test.shape, pred_real.shape)\n",
    "            metric = _calc_metrics(y_test, pred_real, metric_list)\n",
    "\n",
    "            for key, value in metric.items():\n",
    "                history_metric[key].append(value)\n",
    "        \n",
    "        if F > 0:\n",
    "            train_end = L - F\n",
    "            test_start = train_end\n",
    "            test_end = L  # Используем весь остаток\n",
    "\n",
    "            X_train = time_series[:train_end - 1].values.reshape(-1, 1)\n",
    "            y_train = time_series[1:train_end].values.reshape(-1, 1)\n",
    "            y_test = initial_series[test_start:test_end].values.reshape(-1, 1)\n",
    "\n",
    "            model = func(1)\n",
    "            model = model.fit(X_train, y_train)\n",
    "\n",
    "            current = X_train[-1]\n",
    "            pred_logs = []\n",
    "            \n",
    "            for i in range(F):  # Используем остаточную часть\n",
    "                pred_logs.append(model.run(current))\n",
    "                current = pred_logs[i]\n",
    "\n",
    "            pred_real = back_to_real(np.concatenate((time_series[:train_end].values.reshape(-1, 1), \n",
    "                                                    np.array(pred_logs).flatten().reshape(-1, 1))), \n",
    "                                    data_mredc_date['close'][0])[train_end:]\n",
    "\n",
    "            metric = _calc_metrics(y_test, pred_real, metric_list)\n",
    "            for key, value in metric.items():\n",
    "                history_metric[key].append(value)\n",
    "        \n",
    "        model = func(1)\n",
    "        model.fit(time_series[:-1].values.reshape(-1, 1), time_series[1:].values.reshape(-1, 1))\n",
    "\n",
    "        return model, history_metric\n",
    "\n",
    "    elif schema == 'schema_2':\n",
    "        \n",
    "        history_metric = {metric: [] for metric in metric_list}\n",
    "        initial_series = back_to_real(time_series, data_mredc_date['close'][0])\n",
    "        l_ts = len(time_series)\n",
    "\n",
    "        for i in range(0, l_ts-train_size-time_delta, drop_step):\n",
    "            fold = time_series[i:i+train_size+time_delta]\n",
    "            log_fold = np.log(fold).diff().dropna().values.reshape(-1, 1)\n",
    "\n",
    "            X_train = log_fold[:train_size-1]\n",
    "            y_train = log_fold[1:train_size]\n",
    "\n",
    "            y_test = fold[train_size:].values.reshape(-1,1)\n",
    "\n",
    "            model = func(1)\n",
    "            model = model.fit(X_train, y_train)\n",
    "\n",
    "            current = X_train[-1]\n",
    "            pred_logs = []\n",
    "\n",
    "            for j in range(time_delta):\n",
    "                pred_logs.append(model.run(current))\n",
    "                current = pred_logs[j]\n",
    "            pred_real = back_to_real(np.concatenate((log_fold[:train_size], np.array(pred_logs).flatten().reshape(-1,1))), fold.values.reshape(-1,1)[0])[train_size:]\n",
    "            # print(y_test.shape, pred_real.shape)\n",
    "            metric = _calc_metrics(y_test, pred_real, metric_list)\n",
    "\n",
    "\n",
    "            for key, value in metric.items():\n",
    "                history_metric[key].append(value)\n",
    "\n",
    "        fold = time_series[i+drop_step:i+drop_step+train_size+time_delta]\n",
    "        log_fold = np.log(fold).diff().dropna().values.reshape(-1, 1)\n",
    "\n",
    "        model = func(1)\n",
    "        model.fit(log_fold[:train_size-1], log_fold[1:train_size])\n",
    "        \n",
    "        return model, history_metric\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_multi_esn_base(func, input_dim, time_series, time_delta, metric_list, schema='schema_1', drop_step=1, train_size=78):\n",
    "    '''\n",
    "    func: it's a model class, in particular Reservoir class;\n",
    "    input_dim: input dimension. It could be more than 1, but it's important that target value at the last index;\n",
    "    time_series: time series for train and prediction. For \"schema_1\" it should be log_return time series, for \"schema_2\" time series should\n",
    "    contain moving average target feature at the last index;\n",
    "    time_delta: time range for prediction and validation;\n",
    "    metric_list: list of estimating metrics, it can be MAPE, MAE and MSE;\n",
    "    schema: type of cross-validation, in the first option (schema_1) on each step training size is increased by time_delta. Choosing second option\n",
    "    (schema_2) cross-validation you should define 'drop_step' and 'train_size', in this type on each 'drop_step' training set will be moved, so\n",
    "    only 'training_size' window will be used for training;\n",
    "    drop_step: number of point to drop, using in 'schema_2' cross-validation;\n",
    "    train_size: size of time series to use in train in 'schema_2' cross-validation;\n",
    "    '''\n",
    "\n",
    "    if schema == 'schema_1':\n",
    "        L = len(time_series)\n",
    "        N = L // time_delta  # Количество полных fold'ов\n",
    "        F = L % time_delta  # Остаточная часть (конец ряда)\n",
    "\n",
    "        if N < 1:\n",
    "            raise ValueError(\"Change time_delta, not enough data for CV\")\n",
    "\n",
    "        history_metric = {metric: [] for metric in metric_list}\n",
    "        history_metric['preds'] = []\n",
    "        initial_series = back_to_real(data_mredc_date['log_return_close'].dropna(), data_mredc_date['close'][0])\n",
    "\n",
    "        for n in range(1, N+1):\n",
    "\n",
    "            # Индексы для разделения данных\n",
    "            train_end = time_delta * n\n",
    "            test_start = train_end\n",
    "            test_end = test_start + time_delta\n",
    "\n",
    "            # Проверка выхода за границы данных\n",
    "            if test_end > len(initial_series):\n",
    "                break\n",
    "\n",
    "            # Разделение данных\n",
    "            X_train = time_series[:train_end - 1]\n",
    "            y_train = time_series[1:train_end]\n",
    "            y_test = initial_series[test_start:test_end]\n",
    "\n",
    "            # Обучение модели\n",
    "            model = func(input_dim)\n",
    "            model = model.fit(X_train, y_train)\n",
    "\n",
    "            current = X_train[-1]\n",
    "            pred_logs = []\n",
    "            \n",
    "            for i in range(time_delta):\n",
    "                pred_logs.append(model.run(current).reshape(input_dim)[-1])\n",
    "                current = model.run(current).reshape(input_dim)\n",
    "\n",
    "            pred_real = back_to_real(np.concatenate((time_series[:train_end][:,-1].reshape(-1, 1), \n",
    "                                                    np.array(pred_logs).flatten().reshape(-1, 1))), \n",
    "                                    data_mredc_date['close'][0])[train_end:]\n",
    "\n",
    "            metric = _calc_metrics(y_test, pred_real, metric_list)\n",
    "            history_metric['preds'].append(pred_real)\n",
    "            for key, value in metric.items():\n",
    "                history_metric[key].append(value)\n",
    "\n",
    "        # **Добавляем последний fold с остатком данных (если есть остаток)**\n",
    "        if F > 0:\n",
    "            train_end = L - F\n",
    "            test_start = train_end\n",
    "            test_end = L  # Используем весь остаток\n",
    "\n",
    "            X_train = time_series[:train_end - 1]\n",
    "            y_train = time_series[1:train_end]\n",
    "            y_test = initial_series[test_start:test_end]\n",
    "\n",
    "            model = func(input_dim)\n",
    "            model = model.fit(X_train, y_train)\n",
    "\n",
    "            current = X_train[-1]\n",
    "            pred_logs = []\n",
    "            \n",
    "            for i in range(F):  # Используем остаточную часть\n",
    "                pred_logs.append(model.run(current).reshape(input_dim)[-1])\n",
    "                current = model.run(current).reshape(input_dim)\n",
    "\n",
    "            pred_real = back_to_real(np.concatenate((time_series[:train_end][:,-1].reshape(-1, 1), \n",
    "                                                    np.array(pred_logs).flatten().reshape(-1, 1))), \n",
    "                                    data_mredc_date['close'][0])[train_end:]\n",
    "\n",
    "            metric = _calc_metrics(y_test, pred_real, metric_list)\n",
    "            history_metric['preds'].append(pred_real)\n",
    "\n",
    "            for key, value in metric.items():\n",
    "                history_metric[key].append(value)\n",
    "\n",
    "        # **Обучаем модель на всем временном ряде (для финального использования)**\n",
    "        model = func(input_dim)\n",
    "        model.fit(time_series[:-1], time_series[1:])\n",
    "        \n",
    "        return model, history_metric\n",
    "    \n",
    "    elif schema == 'schema_2':\n",
    "        history_metric = {metric: [] for metric in metric_list}        \n",
    "        \n",
    "        initial_series = back_to_real(time_series, data_mredc_date['close'][0])\n",
    "        l_ts = len(time_series)\n",
    "\n",
    "        for i in range(0, l_ts-train_size-time_delta, drop_step):\n",
    "            \n",
    "            fold = time_series[i:i+train_size+time_delta]\n",
    "\n",
    "            y_test = fold.iloc[train_size:, -1].values\n",
    "            fold['log_close'] = np.log(fold['MA_close']).diff()\n",
    "            ma_0 = fold['MA_close'].iloc[0]\n",
    "            fold.drop(columns=['MA_close'], inplace=True)\n",
    "\n",
    "            log_fold = fold.dropna().values\n",
    "\n",
    "            X_train = log_fold[:train_size-1]\n",
    "            y_train = log_fold[1:train_size]\n",
    "\n",
    "            model = func(input_dim)\n",
    "            model = model.fit(X_train, y_train)\n",
    "\n",
    "            current = X_train[-1]\n",
    "            pred_logs = []\n",
    "\n",
    "            for j in range(time_delta):\n",
    "                pred_logs.append(model.run(current).reshape(input_dim)[-1])\n",
    "                current =  model.run(current).reshape(input_dim)\n",
    "                \n",
    "            pred_real = back_to_real(np.concatenate((log_fold[:train_size][:,-1].reshape(-1, 1), np.array(pred_logs).flatten().reshape(-1,1))), ma_0)[train_size:]\n",
    "            # print(y_test.shape, pred_real.shape)\n",
    "            metric = _calc_metrics(y_test, pred_real, metric_list)\n",
    "\n",
    "            for key, value in metric.items():\n",
    "                history_metric[key].append(value)\n",
    "        \n",
    "        fold = time_series[i+drop_step:i+drop_step+train_size+time_delta]\n",
    "        fold['MA_close'], log_fold = np.log(fold['MA_close']).diff(), fold.dropna().values\n",
    "\n",
    "        model = func(input_dim)\n",
    "        model = model.fit(log_fold[:train_size-1], log_fold[1:train_size])\n",
    "\n",
    "        return model, history_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, history_one_esn = cross_validation_esn_base(reset_esn, dmd['log_return_close'].dropna(), 52, ['MAPE', 'MAE'], train_size=104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, history_one_esn_sc2 = cross_validation_esn_base(reset_esn, data_mredc_date.dropna()['MA_close'], 26, ['MAPE', 'MAE'],\n",
    "                                                    schema='schema_2', drop_step=13, train_size=104)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "MULTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, history_multi_esn = cross_validation_multi_esn_base(reset_esn, 4,\n",
    "                                                        dmd[['curs', 'curs_MA',\n",
    "                                                             'infl','log_return_close']].dropna().values,\n",
    "                                                          52, ['MAPE', 'MAE'], train_size=104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, history_multi_esn_sch2 = cross_validation_multi_esn_base(reset_esn, 7,\n",
    "                                                            dmd[['curs', 'curs_laged', 'curs_MA',\n",
    "                                                             'infl', 'curs_MA_laged',\n",
    "                                                             'infl_laged', 'MA_close']].dropna(),\n",
    "                                                               26, ['MAPE', 'MAE'], schema='schema_2', drop_step=13, train_size=104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем DataFrame для визуализации\n",
    "data = pd.DataFrame({\n",
    "    'One-dimensional': np.array(history_one_esn['MAPE']),\n",
    "    'Multi-dimensional': np.array(history_multi_esn['MAPE']),\n",
    "})\n",
    "\n",
    "# Преобразуем данные в длинный формат\n",
    "data_melted = data.melt(var_name='Model', value_name='MAPE')\n",
    "\n",
    "# Настраиваем размер графика\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Рисуем boxplot\n",
    "sns.boxplot(\n",
    "    x='Model', \n",
    "    y='MAPE', \n",
    "    data=data_melted,\n",
    "    hue='Model',\n",
    "    legend=False,\n",
    "    showmeans=True,  # Показываем средние значения\n",
    "    meanprops={'marker':'o', 'markerfacecolor':'black'}\n",
    ")\n",
    "\n",
    "# Добавляем заголовок и подписи\n",
    "plt.title(\"Box-plots of MAPE Errors by cross-validation 'schema_1'\", fontsize=14)\n",
    "plt.xlabel(\"Model Type\", fontsize=12)\n",
    "plt.ylabel(\"MAPE (%)\", fontsize=12)\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Добавляем аннотации\n",
    "plt.text(\n",
    "    x=0.5, y=-0.15, \n",
    "    s='Note: Black circles represent mean values',\n",
    "    fontsize=10, ha='center', transform=plt.gca().transAxes\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylim(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history_multi_esn_sch2['MAPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history_one_esn_sc2['MAPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем DataFrame для визуализации\n",
    "data = pd.DataFrame({\n",
    "    'One-dimensional': np.array(history_one_esn_sc2['MAPE'][2:]),\n",
    "    'Multi-dimensional': np.array(history_multi_esn_sch2['MAPE']),\n",
    "})\n",
    "\n",
    "# Преобразуем данные в длинный формат\n",
    "data_melted = data.melt(var_name='Model', value_name='MAPE')\n",
    "\n",
    "# Настраиваем размер графика\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Рисуем boxplot\n",
    "sns.boxplot(\n",
    "    x='Model', \n",
    "    y='MAPE', \n",
    "    data=data_melted,\n",
    "    hue='Model',\n",
    "    legend=False,\n",
    "    showmeans=True,  # Показываем средние значения\n",
    "    meanprops={'marker':'o', 'markerfacecolor':'black'}\n",
    ")\n",
    "\n",
    "# Добавляем заголовок и подписи\n",
    "plt.title(\"Box-plots of MAPE Errors by cross-validation 'schema_2'\", fontsize=14)\n",
    "plt.xlabel(\"Model Type\", fontsize=12)\n",
    "plt.ylabel(\"MAPE (%)\", fontsize=12)\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Добавляем аннотации\n",
    "plt.text(\n",
    "    x=0.5, y=-0.15, \n",
    "    s='Note: Black circles represent mean values',\n",
    "    fontsize=10, ha='center', transform=plt.gca().transAxes\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylim(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(one_history_sch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history_one_esn_sc2['MAPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "# Box-Plots Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "ROLLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(one_history_sch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history_one_esn_sc2['MAPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Собираем данные вместе\n",
    "data = [history_one_esn_sc2['MAPE'][4:], history_multi_esn_sch2['MAPE'][4:], one_history_sch2, multi_history_sch2['var_0']]\n",
    "\n",
    "# Создаем график\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Рисуем ящики с усами\n",
    "ax.boxplot(data, widths=0.5, showfliers=False, showmeans=True)\n",
    "\n",
    "# Добавляем вертикальную линию, отделяющую первые два ящика от последних двух\n",
    "ax.axvline(x=2.5, color='black', linestyle='--')\n",
    "\n",
    "# Подписи по оси X\n",
    "ax.set_xticklabels(['one-dim ESN', 'multi-dim ESN', 'one-dim ESN-FT', 'multi-dim ESN-FT'])\n",
    "\n",
    "# Подпись оси Y\n",
    "ax.set_ylabel('MAPE, %')\n",
    "\n",
    "# Заголовок (по желанию)\n",
    "# ax.set_title('Сравнение моделей ESN и ESN-FT')\n",
    "\n",
    "# Включаем сетку для удобства\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.ylim(0,15)\n",
    "# Показать график\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "52 точки прогноза и 26 drop_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "EXPANDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history_one_esn['MAPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(multi_history['var_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем данные вместе\n",
    "data = [history_one_esn['MAPE'][:], history_multi_esn['MAPE'][:], one_history, multi_history['var_0']]\n",
    "\n",
    "# Создаем график\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Рисуем ящики с усами\n",
    "ax.boxplot(data, widths=0.5, showfliers=False, showmeans=True)\n",
    "\n",
    "# Добавляем вертикальную линию, отделяющую первые два ящика от последних двух\n",
    "ax.axvline(x=2.5, color='black', linestyle='--')\n",
    "\n",
    "# Подписи по оси X\n",
    "ax.set_xticklabels(['one-dim ESN', 'multi-dim ESN', 'one-dim ESN-FT', 'multi-dim ESN-FT'])\n",
    "\n",
    "# Подпись оси Y\n",
    "ax.set_ylabel('MAPE, %')\n",
    "\n",
    "# Заголовок (по желанию)\n",
    "# ax.set_title('Сравнение моделей ESN и ESN-FT')\n",
    "\n",
    "# Включаем сетку для удобства\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.ylim(0,10)\n",
    "# Показать график\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "# LIGHTGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validation_lg(\n",
    "#     model_factory,\n",
    "#     time_series,\n",
    "#     time_delta,\n",
    "#     cv_type=\"expanding\",\n",
    "#     train_size=None,\n",
    "#     drop_step=None,\n",
    "#     train_full=False\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Perform multi‐step MAPE CV on a 1D series with either expanding or rolling windows,\n",
    "#     working directly on the provided real‐scale time_series.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     model_factory : callable\n",
    "#         Constructor for your model (e.g. EnhancedESN_FAN), must accept input_dim=1\n",
    "#         and implement .fit(X,y) and .run(u).\n",
    "#     time_series : pd.Series or 1D array\n",
    "#         The raw input sequence.\n",
    "#     time_delta : int\n",
    "#         Forecast horizon for each fold.\n",
    "#     cv_type : {\"expanding\",\"rolling\"}\n",
    "#         \"expanding\": train=[0:fold*Δ], test=next Δ points.\n",
    "#         \"rolling\" : train=[start:start+window_size], test=next Δ points.\n",
    "#     window_size : int, optional\n",
    "#         Required if cv_type==\"rolling\". Fixed length of each training window.\n",
    "#     train_full : bool\n",
    "#         If True, refit on the entire series at the end and return that model.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     final_model : object or None\n",
    "#         The model refit on the full series if train_full else None.\n",
    "#     history_mape : List[float]\n",
    "#         One MAPE per fold.\n",
    "#     \"\"\"\n",
    "#     ts = np.asarray(time_series)\n",
    "#     L = len(time_series)\n",
    "\n",
    "#     if cv_type not in (\"expanding\", \"rolling\"):\n",
    "#         raise ValueError(\"cv_type must be 'expanding' or 'rolling'\")\n",
    "\n",
    "#     if cv_type == \"rolling\" and drop_step is None:\n",
    "#         raise ValueError(\"Must specify window_size for rolling CV\")\n",
    "    \n",
    "#     history_mape = []\n",
    "#     history_mae = []\n",
    "\n",
    "#     if cv_type == \"expanding\":\n",
    "#         n_folds = (L-train_size) // time_delta\n",
    "#         F = (L-train_size) % time_delta  # Остаточная часть (конец ряда)\n",
    "#         for fold in range(0, n_folds+1):\n",
    "#             train_end = train_size + fold * time_delta\n",
    "#             test_start = train_end\n",
    "#             test_end   = train_end + time_delta\n",
    "#             if test_end > L:\n",
    "#                 break\n",
    "\n",
    "#             # Build train and test slices\n",
    "#             X_tr = ts[:train_end-1].reshape(-1, 1)\n",
    "#             y_tr = ts[1:train_end].reshape(-1, 1)\n",
    "#             y_true = ts[test_start:test_end].reshape(-1, 1)\n",
    "\n",
    "#             # Fit model\n",
    "#             model = model_factory\n",
    "#             model.fit(X_tr, y_tr)\n",
    "\n",
    "#             # Generative Δ-step forecast\n",
    "#             cur = y_tr[-1]\n",
    "#             preds = []\n",
    "#             for j in range(time_delta):\n",
    "#                 cur = model.predict(cur.reshape(1, -1)).reshape(-1, 1)[0]\n",
    "#                 preds.append(cur)\n",
    "                    \n",
    "#             # Compute MAPE\n",
    "#             mape = mean_absolute_percentage_error(y_true, preds) * 100\n",
    "#             history_mape.append(mape)\n",
    "\n",
    "#             # Compute MAE\n",
    "#             mae = mean_absolute_error(y_true, preds)\n",
    "#             history_mae.append(mae)\n",
    "\n",
    "#         if F > 0:\n",
    "#             train_end = L - F\n",
    "#             test_start = train_end\n",
    "#             test_end = L  # Используем весь остаток\n",
    "\n",
    "#             X_tr = ts[:train_end - 1].reshape(-1, 1)\n",
    "#             y_tr = ts[1:train_end].reshape(-1, 1)\n",
    "#             y_true = ts[test_start:test_end].reshape(-1, 1)\n",
    "\n",
    "#             # Fit model\n",
    "#             model = model_factory\n",
    "#             model.fit(X_tr, y_tr)\n",
    "\n",
    "#             # Generative Δ-step forecast\n",
    "#             cur = y_tr[-1]\n",
    "#             preds = []\n",
    "#             for j in range(F):\n",
    "#                 cur = model.predict(cur.reshape(1, -1)).reshape(-1, 1)[0]\n",
    "#                 preds.append(cur)\n",
    "\n",
    "#             # Compute MAPE\n",
    "#             mape = mean_absolute_percentage_error(y_true, preds) * 100\n",
    "#             history_mape.append(mape)\n",
    "\n",
    "#             # Compute MAE\n",
    "#             mae = mean_absolute_error(y_true, preds)\n",
    "#             history_mae.append(mae)\n",
    "\n",
    "#     else:  # rolling\n",
    "#         for start in range(0, L-train_size-time_delta+1, drop_step):\n",
    "#             train_start = start\n",
    "#             train_end   = start+train_size+time_delta\n",
    "#             test_start  = train_end\n",
    "#             test_end    = test_start + time_delta\n",
    "#             if test_end > L:\n",
    "#                 break\n",
    "\n",
    "#             X_tr = ts[train_start:train_end-1].reshape(-1, 1)\n",
    "#             y_tr = ts[train_start+1:train_end].reshape(-1, 1)\n",
    "#             y_true = ts[test_start:test_end].reshape(-1, 1)\n",
    "\n",
    "#             model = model_factory\n",
    "#             model.fit(X_tr, y_tr)\n",
    "\n",
    "#             # Generative Δ-step forecast\n",
    "#             cur = y_tr[-1]\n",
    "#             preds = []\n",
    "#             for j in range(time_delta):\n",
    "#                 cur = model.predict(cur.reshape(1, -1)).reshape(-1, 1)[0]\n",
    "#                 preds.append(cur)\n",
    "                \n",
    "#             # Compute MAPE\n",
    "#             mape = mean_absolute_percentage_error(y_true, preds) * 100\n",
    "#             history_mape.append(mape)\n",
    "\n",
    "#             # Compute MAE\n",
    "#             mae = mean_absolute_error(y_true, preds)\n",
    "#             history_mae.append(mae)\n",
    "\n",
    "#     final_model = None\n",
    "#     if train_full:\n",
    "#         X_all = ts[:-1].reshape(-1,1)\n",
    "#         y_all = ts[1: ].reshape(-1,1)\n",
    "#         final_model = model_factory.fit(X_all, y_all)\n",
    "\n",
    "#     return final_model, history_mape, history_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lg = LGBMRegressor(random_state=23, verbosity=-1)\n",
    "\n",
    "_, history_mape_lg, lg_mae = cross_validation_lg(lg, dmd.dropna()['MA_close'], cv_type='rolling', drop_step=26, time_delta=52, train_size=104)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Собираем данные вместе\n",
    "# data = [multi_history['var_0'], history_one_esn['MAPE'], history_mape_lg]\n",
    "\n",
    "# # Создаем график\n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# # Рисуем ящики с усами\n",
    "# ax.boxplot(data, widths=0.5, showfliers=False, showmeans=True)\n",
    "\n",
    "# # Подписи по оси X\n",
    "# ax.set_xticklabels(['ESN-F', 'ESN', 'LGBM'])\n",
    "\n",
    "# # Подпись оси Y\n",
    "# ax.set_ylabel('MAPE (%)')\n",
    "\n",
    "# # Заголовок (по желанию)\n",
    "# # ax.set_title('Сравнение моделей ESN и ESN-FT')\n",
    "\n",
    "# # Включаем сетку для удобства\n",
    "# ax.grid(True, linestyle='--', alpha=0.5)\n",
    "# plt.ylim(0,10)\n",
    "# # Показать график\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig('fig3.jpg',transparent=None, dpi=600)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chaos_indic import HurstTraj, NoiseFactor, DimEmb, max_lyapunov, fourier_harmonic_count, ks_entropy_partition\n",
    "\n",
    "# print(\n",
    "#     round(HurstTraj(data_mredc_date['MA_close'].dropna())[2],2), '\\n',\n",
    "#     round(NoiseFactor(data_mredc_date['MA_close'].dropna()),2), '\\n',\n",
    "#     round(DimEmb(data_mredc_date['MA_close'].dropna())[1],2), '\\n',\n",
    "#     round(max_lyapunov(data_mredc_date['MA_close'].dropna().values),2), '\\n',\n",
    "#     round(ks_entropy_partition(data_mredc_date['MA_close'].dropna()),2), '\\n',\n",
    "#     fourier_harmonic_count(data_mredc_date['MA_close'].dropna())\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
